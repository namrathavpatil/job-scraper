name: Job Scraper

on:
  schedule:
    - cron: '0 */4 * * *'  # Run every 4 hours

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Download job history artifact
      uses: actions/download-artifact@v3
      with:
        name: job-history
        path: ./
        if-no-files-found: ignore
    
    - name: Run job scraper
      env:
        WEBHOOK_URL: ${{ secrets.WEBHOOK_URL }}
        AIRTABLE_URL: ${{ secrets.AIRTABLE_URL }}
        RESEARCH_WEBHOOK_URL: ${{ secrets.RESEARCH_WEBHOOK_URL }}
        UNIVERSITY_WEBHOOK_URL: ${{ secrets.UNIVERSITY_WEBHOOK_URL }}
      run: python import_requests.py
    
    - name: Upload job history artifact
      uses: actions/upload-artifact@v3
      with:
        name: job-history
        path: job_history.json
        retention-days: 30  # Keep the artifact for 30 days
